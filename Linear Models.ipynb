{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Linear Models and Validation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yellowbrick.datasets import load_spam\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library:\n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (4600, 57), size of X is 262200, and X is a <class 'pandas.core.frame.DataFrame'>\n",
      "The shape of y is: (4600,), size of y is 4600, and y is a <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "X, y = load_spam()  # X = data , y = target\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"The shape of X is: {}, size of X is {}, and X is a {}\".format(\n",
    "    X.shape, X.size, type(X)))\n",
    "print(\"The shape of y is: {}, size of y is {}, and y is a {}\".format(\n",
    "    y.shape, y.size, type(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in X.\n",
      "There are 0 missing values in y.\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"There are {} missing values in X.\".format(X.isna().sum().sum()))\n",
    "print(\"There are {} missing values in y.\".format(y.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_small is 13110, this represents 5.0 % of the original dataset\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small\n",
    "X_small, X_test_sm, y_small, y_test_sm = train_test_split(\n",
    "    X, y, train_size=0.05, random_state=0)\n",
    "\n",
    "print(\"Size of X_small is {}, this represents {} % of the original dataset\".format(\n",
    "    X_small.size, X_small.size/X.size*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets:\n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set Data Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196650.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6900.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9804.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Set Data Size  Training Accuracy  Validation Accuracy\n",
       "0                196650.0               0.93                 0.94\n",
       "1                  6900.0               0.61                 0.61\n",
       "2                  9804.0               0.94                 0.93"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Visualize results\n",
    "results = pd.DataFrame(\n",
    "    columns=['Training Set Data Size', 'Training Accuracy', 'Validation Accuracy'])\n",
    "\n",
    "X_values = [X, X.iloc[:, [0, 1]], X_small]\n",
    "y_values = [y, y, y_small]\n",
    "\n",
    "for X, y in zip(X_values, y_values):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=0)  # split data into training and testing sets\n",
    "\n",
    "    # instantiate logistic regression model\n",
    "    logreg = LogisticRegression(max_iter=2000)\n",
    "    logreg.fit(X_train, y_train)  # fit the model to the training sets\n",
    "\n",
    "    # create new row in dataframe and add data size, training accuracy, and validation accuracy\n",
    "    results.loc[len(results)] = ([X_train.size, logreg.score(\n",
    "        X_train, y_train), logreg.score(X_test, y_test)])\n",
    "\n",
    "pd.set_option('display.precision', 2)  # set display precision\n",
    "results  # print dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "**1.** The training and validation accuracy change depending on the amount of data and the number of features evaluated in the classification model.\n",
    "\n",
    "The models built using X data and X_small data have about the same training and validation accuracy at (X, y: 0.93 training and 0.94 validation accuracy vs X_small, y_small: 0.94 training and 0.93 validation). This shows:\n",
    "\n",
    "-   that we used a representative 5% of the records (rows) for the X_small, y_small dataset by how similar the training and validation accuracies are,\n",
    "-   that increasing the amount of training data can increase the accuracy but may have deminishing returns once a representative sample of datapoints are include in the model, and\n",
    "-   that changing the amount of data may not impact a high-bias model (changing the model type may have more impact).\n",
    "\n",
    "The dataset with the first 2 columns of X is less accurate (0.61 for both training and validation) than the full or representatively reduced dataset as we reduced the number of features included in the model and the model is still showing high-bias (equal training and validation accuracy scores). The poor training and validation accuracy of the two column model indicates that an accurate spam model depends on more than just word_freq_make word_freq_address to predict spam.\n",
    "\n",
    "**2.** In the spam dataset, a false positive represents when the model marks good data as spam. A false negative in the spam dataset represents spam marked as good data. A false negative is worse as it lets spam through the model/filter leading to potential harm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description\n",
    "\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "1.  Sourced code from:\n",
    "\n",
    "-   course notes, course textbook (Introduction to Machine Learning with Python).\n",
    "-   realpython.com (explaining how to use zip) https://realpython.com/python-zip-function/ and\n",
    "-   saturncloud.com (how to add a row to a dataframe) https://saturncloud.io/blog/how-to-add-new-rows-to-a-pandas-dataframe/\n",
    "\n",
    "2. Completed the steps in the order written as instructed. Steps:\n",
    "\n",
    "-   data input - load spam dataset\n",
    "-   data processing - check for null values and split the data into three sets: full data, reduced feature data, and reduced size data\n",
    "-   ML model - applied a LogisticRegression with a maximum of 2000 iterations to the data.\n",
    "-   validation - used .score() function to produce training and validation accuracy scores for the three datasets.\n",
    "\n",
    "3. Did not use generative AI.\n",
    "4. Challenged by how to get the different datasets inside of a loop. Initially didn't understand that we needed to call train_test_split again within the loop. Reviewing lab jupyter notebooks and viewing other course code helped to see how other similar problems were coded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library:\n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1030, 8), size of X is 8240, and X is a <class 'pandas.core.frame.DataFrame'>\n",
      "The shape of y is: (1030,), size of y is 1030, and y is a <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "X, y = load_concrete()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"The shape of X is: {}, size of X is {}, and X is a {}\".format(\n",
    "    X.shape, X.size, type(X)))\n",
    "print(\"The shape of y is: {}, size of y is {}, and y is a {}\".format(\n",
    "    y.shape, y.size, type(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in X.\n",
      "There are 0 missing values in y.\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"There are {} missing values in X.\".format(X.isna().sum().sum()))\n",
    "print(\"There are {} missing values in y.\".format(y.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# training accuracy\n",
    "y_pred_train = lr.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# validation accuracy\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.36</td>\n",
       "      <td>95.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training accuracy  Validation accuracy\n",
       "MSE                  111.36                95.90\n",
       "R2 Score               0.61                 0.62"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# create dataframe with columns\n",
    "results = pd.DataFrame(columns=['Training accuracy', 'Validation accuracy'])\n",
    "# create index and add accuracy results\n",
    "results.loc['MSE'] = ([mse_train, mse])\n",
    "# create index and add accuracy results\n",
    "results.loc['R2 Score'] = ([r2_train, r2])\n",
    "pd.set_option('display.precision', 2)  # set display precision\n",
    "results  # print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "The linear model did not produce good results with low R2 scores and high MSE scores. These indicate that a the linear model is likely not appropriate for the data.\n",
    "\n",
    "The R2 score should be close to 1.0 and the model scored 0.61 and 0.62 on the training and validation sets indicate that there is a lot of variability between the actual and predicted values. The similarity in value of the R2 score suggests that the model is underfitting.\n",
    "\n",
    "The MSE is 111.36 (training) and 95.90 (validation). The ideal MSE is close to 0. The high MSE indicates that the average error between actual and predicted values is quite large, again indicating that the model is underfitting the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description\n",
    "\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "_Answers_\n",
    "\n",
    "**1.** Source code:\n",
    "\n",
    "-   course notes, course textbook (Introduction to Machine Learning with Python).\n",
    "\n",
    "-   Assistance with R2 and MSE: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "\n",
    "-   Assistance with understanding what MSE means: https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "**2.** Completed the steps in the order presented in the jupyter notebook. Steps:\n",
    "\n",
    "-   data input - load concrete data\n",
    "-   data processing - check for null values\n",
    "-   ML model - Applied a LinearRegression to the data.\n",
    "-   validation - used r_score() function to produce training and validation accuracy scores that shows the goodness of fit of a model. Used the mean_squared_error() function to measure how close the model is to the data points.\n",
    "\n",
    "**3.** Did not use generative AI\n",
    "\n",
    "**4.** Challenges understanding the difference in .score(), mean_squared_error(), and r2_score(). Reading the textbook, course notes, and asking google helped to increase my understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "-   Found that accuracy scores can be a good indication that the model being used is inappropriate for the data. For example, applying linear regression model on concrete showed that a low R2 score (0.62) and high MSE score (95.9). This is because the compressive strength of concrete is known to be a non-linear model thus showing what would happen if an inappropriate model is applied to a dataset.\n",
    "\n",
    "-   Found that the more features included in the model increased the chance of having a high accuracy score. The spam dataset reduced by fetures showed that the same data when drastically reduced by features had a much lower accuracy score (0.94 with whole data vs 0.61 with reduced features). This likely has an optimum point and beyond which the addition of more features begins to reduce the accuracy of the model.\n",
    "\n",
    "-   Found that the number of records/rows doesn't necessarily impact the data accuracy as much as the number of features. Using 5% of the whole dataset then further split into testing and training data revealed very similar accuracy scores (0.94 with whole data vs 0.93 with reduced data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 4: Bonus Question\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df9b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split into testing and training sets\n",
    "X, y = load_concrete()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge alpha=1.0 training set score 0.61\n",
      "Ridge alpha=1.0 validation score 0.62\n"
     ]
    }
   ],
   "source": [
    "# Ridge alpha=1.0\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1.0, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Ridge alpha=1.0 training set score %.2f\" %\n",
    "      ridge.score(X_train, y_train))\n",
    "print(\"Ridge alpha=1.0 validation score %.2f\" % ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21d8305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge alpha=0.01 training set score 0.61\n",
      "Ridge alpha=0.01 validation score 0.62\n"
     ]
    }
   ],
   "source": [
    "# Ridge alpha=0.01\n",
    "ridge01 = Ridge(alpha=0.01, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Ridge alpha=0.01 training set score %.2f\" %\n",
    "      ridge01.score(X_train, y_train))\n",
    "print(\"Ridge alpha=0.01 validation score %.2f\" % ridge01.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc0550d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge alpha=100 training set score 0.61\n",
      "Ridge alpha=100 validation score 0.62\n"
     ]
    }
   ],
   "source": [
    "# Ridge alpha=100\n",
    "ridge100 = Ridge(alpha=100, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Ridge alpha=100 training set score %.2f\" %\n",
    "      ridge100.score(X_train, y_train))\n",
    "print(\"Ridge alpha=100 validation score %.2f\" % ridge100.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd9206ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.61\n",
      "Validation score 0.62\n",
      "Number of features used in the model:  8\n"
     ]
    }
   ],
   "source": [
    "# Lasso alpha=1.0\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1.0, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Training set score %.2f\" % lasso.score(X_train, y_train))\n",
    "print(\"Validation score %.2f\" % lasso.score(X_test, y_test))\n",
    "print(\"Number of features used in the model: \", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb10244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.47\n",
      "Validation score 0.51\n",
      "Number of features used in the model:  5\n"
     ]
    }
   ],
   "source": [
    "# Lasso alpha=100\n",
    "lasso100 = Lasso(alpha=100, max_iter=2000).fit(X_train, y_train)\n",
    "print(\"Training set score %.2f\" % lasso100.score(X_train, y_train))  # R2 score\n",
    "print(\"Validation score %.2f\" % lasso100.score(X_test, y_test))   # R2 score\n",
    "print(\"Number of features used in the model: \", np.sum(lasso100.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "_Answers_\n",
    "\n",
    "The ordinary least squares method produced the best R2 score.\n",
    "\n",
    "The model does not have high variance so the model did not respond to regularization.\n",
    "\n",
    "With ridge regression, the training and validation scores did not change from the ordinary least squares method values.\n",
    "\n",
    "With lasso regression, the training and validation scores did not respond until the regularization increased and the model became less complex with 5 out of the 8 features being considered in the model. Here, both the training and validation score decreased suggesting the model moved toward underfitting and higher bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eecc49",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
