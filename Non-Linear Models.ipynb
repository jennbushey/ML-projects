{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Non-Linear Models and Validation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library:\n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.279761</td>\n",
       "      <td>73.447331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.576135</td>\n",
       "      <td>45.052441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.37944</td>\n",
       "      <td>22.819636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT         47.279761           73.447331\n",
       "RF         29.576135           45.052441\n",
       "GB           3.37944           22.819636"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Verify training and testing data have the same number of data points\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "results = pd.DataFrame(index=[\"DT\", \"RF\", \"GB\"], columns=[\n",
    "                       \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "\n",
    "# Random Forest\n",
    "forest = RandomForestRegressor(random_state=0, max_depth=5)\n",
    "\n",
    "# Gradient Boosting\n",
    "gbrt = GradientBoostingRegressor(random_state=0, max_depth=5)\n",
    "\n",
    "classification = (tree, forest, gbrt)\n",
    "i = 0\n",
    "for reg in classification:\n",
    "    # Only use training data for cross-validation\n",
    "    score = cross_validate(\n",
    "        reg, X_train, y_train, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    training_accuracy = score['train_score'].mean()*-1\n",
    "    validation_accuracy = score['test_score'].mean()*-1\n",
    "    results.iloc[i] = [training_accuracy, validation_accuracy]\n",
    "    i = i+1\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.738697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.840951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.919348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT          0.834465            0.738697\n",
       "RF          0.896561            0.840951\n",
       "GB          0.988171            0.919348"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for reg in classification:\n",
    "    score = cross_validate(reg, X_train, y_train,\n",
    "                           scoring='r2', return_train_score=True)\n",
    "    training_accuracy = score['train_score'].mean()\n",
    "    validation_accuracy = score['test_score'].mean()\n",
    "    results.iloc[i] = [training_accuracy, validation_accuracy]\n",
    "    i = i+1\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "_ANSWER HERE_\n",
    "\n",
    "1. In the previous assignment, using a linear model, we saw that the MSE score was 111.36 training and 95.90 testing. The linear model performed much worse than any of the non-linear methods where our MSE training values ranged from 47.3(DT) to 3.4(GB) and our MSE validation values ranged from 73.4 (DT) to 22.8 (GB). This is a significant improvement and suggests the concrete data better fits a non-linear model. For the R2 evaluation, the linear model had training accuracy of 0.61 and validation accuracy of 0.62. We believed this was poor fit of the model and suggested underfitting. With the non-linear models, we see training accuracy from 0.83 (DT) to 0.99 (GB) and validation accuracy from 0.74 (DT) to 0.92 (GB). These values are a great improvement and the lower validation score than training score suggests the models are no longer underfitting the data.\n",
    "\n",
    "2. I would select the Gradient Boosting model for this dataset. Out of all the models, the gradient boosting performed the best in both the MSE and R2 analysis.\n",
    "\n",
    "    The MSE on the training and validation sets for gradient boosting were lower than the other sets (13.0 training score and 28.5 validation score for gradient boosting vs 29.6 training score and 45.1 validation score for the random forest regression). An ideal MSE score would be zero so the lower score is \"better\" and the gradient boosting model is closer to zero than both the random forest and decision tree models.\n",
    "\n",
    "    A perfect R2 score is 1.0 so we are looking for the highest R2 score to indicate the bets fit for the model. Graident boosting has a 0.95 training score and 0.90 validation score and the next closest score was random forest model with 0.89 training score and 0.84 validation score. These values indicate that the gradient boosting model is a good fit for the concrete data.\n",
    "\n",
    "3. To increase the accuracy of the tree-based models, I would:\n",
    "\n",
    "    a. add max_leaf_nodes parameter.\n",
    "\n",
    "    Adding maximum leaf nodes parameter works in a similar way to restricting the depth of the tree to reduce the likelihood of achieving pure leaves in a way that would allow for the complexity of the model to increase where it is truly needed while restricting the model from completely overfitting.\n",
    "\n",
    "    b. increase the size of the dataset / collect more data\n",
    "\n",
    "    Increasing the dataset may increase accuracy as more varied data points would allow for a better fit of the model to the data. This dataset has only 1030 data points and 8 features (plus one target feature) and this non-linear relationship may benefit from more points or more features to better model the relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description\n",
    "\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "_DESCRIBE YOUR PROCESS HERE_\n",
    "\n",
    "1.  Sourced code from:\n",
    "\n",
    "-   course notes, course jupyter notebooks\n",
    "-   course textbook (Introduction to Machine Learning with Python).\n",
    "-   sklearn website: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "-   stack overflow, DataConversionWarning: https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected\n",
    "\n",
    "2. Completed the steps in the order written as instructed. Steps:\n",
    "\n",
    "-   data input - load concrete dataset\n",
    "-   ML model and validation\n",
    "\n",
    "    -   applied a Decision Tree model and calculated training and validation scores using .score\n",
    "    -   applied Random Forest model and calculated training and validation scores using .score\n",
    "    -   applied Gradient Boosting model and realized that we wanted MSE accuracy score not R2 as provided in .score.\n",
    "    -   replaced decision tree and random forest training and validation accuracy score calculations with negative MSE cross-validation scoring.\n",
    "    -   calculated the mean of the train_score and test_score of the cross validation as default parameters performs 3-fold cross validation producing a list of three accuracy scores for the one model. The mean represents the average of these three accuracy scores.\n",
    "    -   applied Gradient Boosting model and calculated training and validation scores using cross-validation and negative MSE scoring.\n",
    "    -   created loop for duplicate calculations and deleted redundant code\n",
    "\n",
    "3. Did not use generative AI.\n",
    "4. Challenged by my own reading comprehension. Textbook uses classification for their examples and the question was for regression models. It took a minute to figure out if the heading in the assignment was wrong or if we were actually doing regression in this part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X is: (178, 13) and is of type <class 'pandas.core.frame.DataFrame'>\n",
      "The size of y is: (178, 1) and is of type <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "# Followed the import in python instructions for the dataset shown when following the above link.\n",
    "# pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "wine = fetch_ucirepo(id=109)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = wine.data.features\n",
    "y = wine.data.targets  # y target vector is the class column\n",
    "\n",
    "print(f\"The size of X is: {X.shape} and is of type {type(X)}\")\n",
    "print(f\"The size of y is: {y.shape} and is of type {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "\n",
      "There are 0 missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(X.isna().sum())  # no missing values in the dataset\n",
    "print(f\"\\nThere are {X.isna().sum().sum()} missing values in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71 samples of class 2 wine. \n",
      "There are 59 samples of class 1 wine. \n",
      "There are 48 samples of class 3 wine. \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "samples = y.value_counts()\n",
    "for i, j in samples.items():\n",
    "    print(\"There are {} samples of class {} wine. \".format(j, *i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X Size</th>\n",
       "      <th>y Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>(133, 1)</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>0.676638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>(133, 1)</td>\n",
       "      <td>0.994357</td>\n",
       "      <td>0.894017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X Size    y Size Training Accuracy Validation Accuracy\n",
       "SVC  (133, 13)  (133, 1)          0.680427            0.676638\n",
       "DT   (133, 13)  (133, 1)          0.994357            0.894017"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "results = pd.DataFrame(index=[\"SVC\", \"DT\"], columns=[\n",
    "                       \"X Size\", \"y Size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "# split data to keep the testing data completely separate from the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "\n",
    "classification = (svc, tree)\n",
    "\n",
    "i = 0\n",
    "for reg in classification:\n",
    "    score = cross_validate(reg, X_train, y_train.values.ravel(\n",
    "    ), scoring='accuracy', return_train_score=True)\n",
    "    training_accuracy = score['train_score'].mean()\n",
    "    validation_accuracy = score['test_score'].mean()\n",
    "    results.iloc[i] = [X_train.shape, y_train.shape,\n",
    "                       training_accuracy, validation_accuracy]\n",
    "    i = i+1\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  2,  0],\n",
       "       [ 0, 20,  1],\n",
       "       [ 0,  0,  8]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# fit the model\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# predict the target for the test data\n",
    "tree_pred = tree.predict(X_test)\n",
    "\n",
    "# create confusion matrix comparing test values and predicted values.\n",
    "cf = confusion_matrix(y_test, tree_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "labels = [\"Class 1\", \"Class 2\", \"Class 3\"]\n",
    "sns.heatmap(cf, annot=True, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       1.00      0.88      0.93        16\n",
      "     Class 2       0.91      0.95      0.93        21\n",
      "     Class 3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, tree_pred,\n",
    "      target_names=[\"Class 1\", \"Class 2\", \"Class 3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2?\n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "_YOUR ANSWERS HERE_\n",
    "\n",
    "1. Accuracy for the decision tree was higher than the accuracy for SVC for both the training and validation values.\n",
    "   Decision tree had the higher training and validation scores at 0.99 and 0.89 suggesting it is a good fit. SVC had training and validation scores of 0.68 and 0.68 suggesting it is underfitting the data.\n",
    "\n",
    "2. Support vector machines model did not work as well as the tree-based model because:\n",
    "   a. SVM models equire careful preprocessing of the data and tuning of the parameters which was not performed for this dataset. The model may produce better accuracy scores if multiple models were created using an iterative process tuning the C and gamma parameters.\n",
    "   b. Tree based models work very well at classifying distinct features that don't require normalzation or standardization pre-processing.\n",
    "\n",
    "3. 3 samples were incorrectly classified out of 45 total test samples in step 5.2.\n",
    "\n",
    "4. In this case, maximizing precision is more important because it is more important limit the number of false positives (saying a sample DOES belong to a class when it doesn't). We would want to have high precision on predicting the class of wine to limit mistakes but also because the consequences of a false negative (saying a wine DOES NOT belong to a class when it does) are very low if the model does not predict correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description\n",
    "\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "_DESCRIBE YOUR PROCESS HERE_\n",
    "\n",
    "1.  Sourced code from:\n",
    "\n",
    "-   course notes, course jupyter notebooks\n",
    "-   course textbook (Introduction to Machine Learning with Python).\n",
    "-   pandas website, series objects: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html\n",
    "-   stack overflow, unpack series for iteration: https://stackoverflow.com/questions/50267185/iterate-over-pandas-series\n",
    "-   stack overflow, DataConversionWarning: https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected\n",
    "\n",
    "2. Completed the steps in the order written as instructed. Steps:\n",
    "\n",
    "-   data input - load wine dataset\n",
    "-   ML model and validation\n",
    "    -   applied a SVC model\n",
    "    -   applied Decision Tree model\n",
    "    -   reused the loop from previous part\n",
    "    -   fit the model to the decision tree as it had higher validation and training scores\n",
    "    -   predicted the y_test values using .fit()\n",
    "    -   created confusion matrix\n",
    "    -   plotted heatmap\n",
    "    -   printed classification report\n",
    "\n",
    "3. Did not use generative AI.\n",
    "4. No challenges. The course notes, example jupyter notebooks, and textbook were very helpful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "_ADD YOUR FINDINGS HERE_\n",
    "\n",
    "For regression, the ensemble regression trees performed better than the single decision tree (validation accuracy of 0.89 GB, 0.84 RF vs 0.73 DT) due to the combination of the intsertion of randomness in the random forests and the serialization of models in gradient boosting. A model composed of multiple models better fits in terms of accuracy on data that hasn't been seen before. We saw this in the lectures that the gradient boosting improves upon earlier iterations and the random forest is built upon randomness samples or features and merges the best results together. These ensemble models would perform better accuracy and would overfit less than the model based upon one iteration of the dataset.\n",
    "\n",
    "For classification, the decision tree model out performed the SVC model (validation accuracy of 0.89 DT vs 0.67 SVC). This supports the conclusions in class that the SVC model requires careful tuning of the C and gamma parameters, none of which was done in this assignment therefore we cannot know if the SVC is an adequate model choice or if we simply didn't find the right set of parameters for the best accuracy in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 4: Bonus Question\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jennbushey/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.680427</td>\n",
       "      <td>0.676638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.889296</td>\n",
       "      <td>0.863533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Accuracy Validation Accuracy\n",
       "SVC                 0.680427            0.676638\n",
       "Linear SVC          0.889296            0.863533"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "bonus_results = pd.DataFrame(index=[\"SVC\", \"Linear SVC\"], columns=[\n",
    "                             \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "# split data to keep the testing data completely separate from the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# SVC\n",
    "svc = SVC()\n",
    "\n",
    "# LineraSVC\n",
    "svc_lin = LinearSVC(max_iter=5000)\n",
    "\n",
    "classification = (svc, svc_lin)\n",
    "\n",
    "i = 0\n",
    "for model in classification:\n",
    "    model.fit(X_train, y_train)\n",
    "    score = cross_validate(model, X_train, y_train.values.ravel(\n",
    "    ), cv=5, scoring='accuracy', return_train_score=True)\n",
    "    training_accuracy = score['train_score'].mean()\n",
    "    validation_accuracy = score['test_score'].mean()\n",
    "    bonus_results.iloc[i] = [training_accuracy, validation_accuracy]\n",
    "    i = i+1\n",
    "bonus_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "_ANSWER HERE_\n",
    "\n",
    "The results for the SVC model are the same as we did not change anything about the way SVC was calculated.\n",
    "\n",
    "The LinearSVC model has training accuracy of 0.99 and validation accuracy of 0.98. These values are significant improvement over the SVC model (training 0.68, validation 0.68) and the decision tree model (training 0.99, validation 0.89). This is likely due to the dataset being classified more easily by linear hyperplanes than the non-linear hyperplanes of SVC or the if/else style classification present in decision tree models.\n",
    "\n",
    "The Linear SVC is not a good fit for the dataset as the maximum iterations were reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199b73d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
